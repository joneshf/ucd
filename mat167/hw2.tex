\documentclass[12pt,letterpaper]{article}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{cancel}
\usepackage[margin=1in]{geometry}
\usepackage{titling}

\setlength{\droptitle}{-10ex}

\preauthor{\begin{flushright}\large \lineskip 0.5em}
\postauthor{\par\end{flushright}}
\predate{\begin{flushright}\large}
\postdate{\par\end{flushright}}

\title{MAT 167 Homework 2\vspace{-2ex}}
\author{Hardy Jones\\
        999397426\\
        Professor Cheer\vspace{-2ex}}
\date{Winter 2014}

\begin{document}
  \maketitle

  \section*{1.7}
    \subsection*{4}
      Write down the 3 by 3 finite-difference matrix equation ($h = \frac{1}{4}$) for
      \[-\frac{d^2u}{dx^2} + u = x, \qquad u(0) = u(1) = 0\].

      Following from the text

      \[\frac{d^2u}{dx^2} \approx \frac{\Delta^2u}{\Delta x^2} = \frac{u(x+h) - 2u(x) + u(x-h)}{h^2}\]

      So we have

      \[-\frac{u(x+h) - 2u(x) + u(x-h)}{h^2} + u = x\]

      Letting $x = jh$, and realizing that $u$ must be a function of $x$

      \begin{align*}
        -\frac{u(jh+h) - 2u(jh) + u(jh-h)}{h^2} + u(jh) &= jh \\
        -\frac{u((j+1)h) - 2u(jh) + u((j-1)h)}{h^2} + u(jh) &= jh \\
        -u((j+1)h) + 2u(jh) - u((j-1)h) + u(jh)h^2 &= jh^3
      \end{align*}

      We take another cue from the text and use the notation $u(jh) = u_j$
      \begin{align*}
        -u_{j+1} + 2u_j - u_{j-1} + u_jh^2 &= jh^3 \\
        -u_{j+1} + u_jh^2 + 2u_j - u_{j-1} &= jh^3 \\
        -u_{j+1} + (h^2 + 2)u_j - u_{j-1} &= jh^3
      \end{align*}

      Since we have $h = \frac{1}{4}$

      \begin{align*}
        -u_{j+1} + ((\tfrac{1}{4})^2 + 2)u_j - u_{j-1} &= j(\tfrac{1}{4})^3 \\
        -u_{j+1} + (\tfrac{1}{16} + 2)u_j - u_{j-1} &= \tfrac{j}{64}
        -u_{j+1} + \tfrac{33}{16}u_j - u_{j-1} &= \tfrac{j}{64}
      \end{align*}

      Now we check each of $j = 1,2,3$, remembering $u(0) = u_0 = u(1) = u_4 = 0$

      $j = 1$
      \begin{align*}
        -u_{1+1} + \tfrac{33}{16}u_1 - u_{1-1} &= \tfrac{1}{64} \\
        -u_2 + \tfrac{33}{16}u_1 - u_0 &= \tfrac{1}{64} \\
        -u_2 + \tfrac{33}{16}u_1 &= \tfrac{1}{64}
      \end{align*}

      $j = 2$
      \begin{align*}
        -u_{2+1} + \tfrac{33}{16}u_2 - u_{2-1} &= \tfrac{2}{64} \\
        -u_{3} + \tfrac{33}{16}u_2 - u_{1} &= \tfrac{2}{64}
      \end{align*}

      $j = 3$
      \begin{align*}
        -u_{3+1} + \tfrac{33}{16}u_3 - u_{3-1} &= \tfrac{3}{64} \\
        -u_{4} + \tfrac{33}{16}u_3 - u_{2} &= \tfrac{3}{64} \\
        \tfrac{33}{16}u_3 - u_{2} &= \tfrac{3}{64}
      \end{align*}

      So we have
      \begin{align*}
        -u_2 + \tfrac{33}{16}u_1 &= \tfrac{1}{64} \\
        -u_{3} + \tfrac{33}{16}u_2 - u_{1} &= \tfrac{2}{64} \\
        \tfrac{33}{16}u_3 - u_{2} &= \tfrac{3}{64}
      \end{align*}

      Rearranging
      \begin{align*}
        \tfrac{33}{16}u_1 - u_2 &= \tfrac{1}{64} \\
        -u_{1} + \tfrac{33}{16}u_2 - u_{3}&= \tfrac{2}{64} \\
        -u_{2} + \tfrac{33}{16}u_3 &= \tfrac{3}{64}
      \end{align*}

      \[
        \left[
        \begin{array}{ccc}
        \tfrac{33}{16} & -1             & 0              \\
        -1             & \tfrac{33}{16} & -1             \\
        0              & -1             & \tfrac{33}{16}
        \end{array}
        \right]
        \left[
        \begin{array}{c}
        u_1 \\
        u_2 \\
        u_3
        \end{array}
        \right]
        =
        \frac{1}{64}
        \left[
        \begin{array}{c}
        1 \\
        2 \\
        3
        \end{array}
        \right]
      \]
    \subsection*{8}
      For the same matrix
      \[
        H = \left[
        \begin{array}{ccc}
        1           & \frac{1}{2} & \frac{1}{3} \\
        \frac{1}{2} & \frac{1}{3} & \frac{1}{4} \\
        \frac{1}{3} & \frac{1}{4} & \frac{1}{5}
        \end{array}
        \right]
      \]
      compare the right-hand sides of $Hx = b$ when the solutions are
      $x_1 = (1,1,1)$ and $x_2 = (0,6,-3.6)$

      \[
        Hx_1 =
        \left[
        \begin{array}{c}
        1.833 \\
        1.083 \\
        0.783
        \end{array}
        \right]
        ,
        Hx_2 =
        \left[
        \begin{array}{c}
        1.800 \\
        1.100 \\
        0.780
        \end{array}
        \right]
      \]
    \subsection*{10}
      Compare the pivots in direct elimination to those with partial pivoting for
      \[
        A =
        \left[
        \begin{array}{cc}
        .001 & 0    \\
        1    & 1000
        \end{array}
        \right]
      \]

      So the pivots are $.001$ and $1000$ with direct elimination.
      After rescaling, the pivots are $1$ and $1000$.

      With partial pivoting, we swap the rows initially.

      \[
        A =
        \left[
        \begin{array}{cc}
        1    & 1000 \\
        .001 & 0
        \end{array}
        \right]
      \]
      Then eliminate.
      \[
        A =
        \left[
        \begin{array}{cc}
        1    & 1000 \\
        .001 & 0
        \end{array}
        \right]
        =
        \left[
        \begin{array}{cc}
        1 & 1000 \\
        0 & -1
        \end{array}
        \right]
      \]

      So the pivots are $1$ and $-1$ with partial pivoting.
      These are much better pivots, as the pivots are similar in magnitude.

  \section*{2.1}
    \subsection*{4}
      What is the smallest subspace of 3 by 3 matrices that contains all symmetric matrices and all lower triangular matrices?
      What is the largest subspace that is contained in both of those subspaces?

      The smallest subspace containing both symmetric matrices and lower triangular matrices is the set of all 3 by 3 matrices.
      It must be the entire subspace since we have to be able to add symmetric matrices to lower triangular matrices. This combination would end up with matrices that have entries above and below the diagonal, though not necessarily symmetric or lower triangular.

      The largest subspace in both the subspace of all symmetric matrices, let's call it $\mathcal{S}$, and the subspace of all lower triangular matrices, let's call it $\mathcal{L}$, would be the set of all diagonal matrices, since every diagonal matrix would be symmetric and would also be lower triangular.
    \subsection*{5}
      \begin{enumerate}
        \item
          Suppose addition in $\mathbf{R}^2$
          adds an extra $1$ to each component,
          so that $(3, 1)$ + $(5, 0)$ equals $(9, 2)$ instead of $(8, 1)$.
          With scalar multiplication unchanged,
          which rules are broken?

          Rules 3, 7, and 8 are broken.

        \item
          Show that the set of all positive real numbers,
          with $x+y$ and $cx$ redeﬁned to equal the usual $xy$ and $x^c$,
          is a vector space.
          What is the ``zero vector''?

          \begin{enumerate}
            \item Since multiplication is commutative, $x + y = y + x$.
            \item Since multiplication is associative, $x + (y + z) = (x + y) + z$.
            \item The zero vector is $1$, since $1x = x$, $\forall x$.
            \item Every vector has its inverse as $\frac{1}{x}$, such that $x \cdot \frac{1}{x} = 1$
            \item $x^1 = x$.
            \item $x^{(c_1c_2)} = (x^{c_1})^{c_2}$.
            \item $(xy)^c = x^cy^c$
            \item $x^{(c_1+c_2)} = x^{c_1}x^{c_2}$
          \end{enumerate}

        \item
          Suppose $(x1, x2) + (y1, y2)$ is defined to be $(x1 + y2, x2 + y1)$.
          With the usual $cx = (cx1, cx2)$,
          which of the eight conditions are not satisﬁed?

          Rules 1, 2, 4 and 8 are broken.
      \end{enumerate}
    \subsection*{10}
    \subsection*{24}
    \subsection*{28}

  \section*{2.2}
    \subsection*{6}
    \subsection*{13}
    \subsection*{25}
    \subsection*{30}
    \subsection*{39}
    \subsection*{53}

  \section*{2.3}
    \subsection*{8}
    \subsection*{16}
    \subsection*{20}
    \subsection*{26}
    \subsection*{30}
    \subsection*{42}
\end{document}
